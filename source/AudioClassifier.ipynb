{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34dd96db-b0ba-47e2-9b38-8d2499301d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import vggish_slim, vggish_params, vggish_input\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecec424c-da91-44b6-8c0e-0ae0e1ec4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, directory, batch_size=32, shuffle=True):\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        self.class_names = ['porn', 'normal']\n",
    "        for class_index, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(directory, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for file_name in os.listdir(class_dir):\n",
    "                    self.file_paths.append(os.path.join(class_dir, file_name))\n",
    "                    self.labels.append(class_index)\n",
    "        self.on_epoch_end()\n",
    "        self.sess, self.features_tensor, self.embeddings_tensor = self.load_vggish_model()\n",
    "\n",
    "    def load_vggish_model(self):\n",
    "        embeddings_tensor = vggish_slim.define_vggish_slim(training=False)\n",
    "        sess = tf.compat.v1.Session()\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, 'vggish_model.ckpt')\n",
    "        features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "        return sess, features_tensor, embeddings_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__data_generation(batch_paths, batch_labels)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.file_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch_paths, batch_labels):\n",
    "        X = np.empty((self.batch_size, 128))  # VGGish embeddings are 128-D\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        for i, (file_path, label) in enumerate(zip(batch_paths, batch_labels)):\n",
    "            examples_batch = vggish_input.wavfile_to_examples(file_path)\n",
    "            [embeddings] = self.sess.run([self.embeddings_tensor], feed_dict={self.features_tensor: examples_batch})\n",
    "            embeddings_mean = np.mean(embeddings, axis=0)  # Average embeddings across examples\n",
    "            X[i,] = embeddings_mean\n",
    "            y[i] = label\n",
    "        y = tf.keras.utils.to_categorical(y, num_classes=len(self.class_names))\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c35fcf49-bd9c-456f-8ad3-923a8ae6286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a6efca5-089e-4799-bbd6-d03c6a1ff830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_paths_and_labels(porn_dir, normal_dir):\n",
    "    \"\"\"Collects file paths and assigns labels based on the directory structure.\"\"\"\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Process porn directory\n",
    "    for file_name in os.listdir(porn_dir):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_paths.append(os.path.join(porn_dir, file_name))\n",
    "            labels.append(1)  # Label for porn class\n",
    "    \n",
    "    # Process normal directory\n",
    "    for file_name in os.listdir(normal_dir):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_paths.append(os.path.join(normal_dir, file_name))\n",
    "            labels.append(0)  # Label for normal class\n",
    "    \n",
    "    return file_paths, labels\n",
    "\n",
    "\n",
    "def _get_real_audio_examples_batch(file_paths, labels, batch_size):\n",
    "    \"\"\"Returns a shuffled batch of examples from real audio files.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list of str): List of file paths to the audio files.\n",
    "        labels (list of int): List of corresponding labels.\n",
    "        batch_size (int): Number of samples in the batch.\n",
    "        sr (int): Sampling rate for audio files.\n",
    "        n_mels (int): Number of mel bands to generate.\n",
    "        n_frames (int): Number of frames in each mel spectrogram.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (features, labels) where features is a NumPy array of shape\n",
    "        [batch_size, num_frames, num_mels] and labels is a NumPy array of shape\n",
    "        [batch_size, num_classes].\n",
    "    \"\"\"\n",
    "    # Ensure the batch size does not exceed the number of available samples\n",
    "    batch_size = min(batch_size, len(file_paths))\n",
    "    \n",
    "    # Randomly select batch_size number of file paths and their corresponding labels\n",
    "    selected_indices = np.random.choice(len(file_paths), batch_size, replace=False)\n",
    "    batch_paths = [file_paths[i] for i in selected_indices]\n",
    "    batch_labels = [labels[i] for i in selected_indices]\n",
    "\n",
    "    features = []\n",
    "    one_hot_labels = []\n",
    "\n",
    "    for file_path, label in zip(batch_paths, batch_labels):\n",
    "        # Load the audio file\n",
    "        y= vggish_input.wavfile_to_examples(file_path)\n",
    "        \n",
    "        features.append(y)\n",
    "\n",
    "        # Convert label to one-hot\n",
    "        one_hot_label = tf.keras.utils.to_categorical(label, num_classes=2)\n",
    "        one_hot_labels.append(one_hot_label)\n",
    "\n",
    "    features = np.array(features)\n",
    "    one_hot_labels = np.array(one_hot_labels)\n",
    "\n",
    "    # Shuffle features and labels together\n",
    "    labeled_examples = list(zip(features, one_hot_labels))\n",
    "    shuffle(labeled_examples)\n",
    "\n",
    "    # Separate and return the features and labels\n",
    "    features = np.array([example for (example, _) in labeled_examples])\n",
    "    labels = np.array([label for (_, label) in labeled_examples])\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def count_files(directory1, directory2):\n",
    "    # Initialize counts for each directory\n",
    "    count = 0\n",
    "\n",
    "    # Count files in directory 1\n",
    "    for _, _, files in os.walk(directory1):\n",
    "        count += len(files)\n",
    "\n",
    "    # Count files in directory 2\n",
    "    for _, _, files in os.walk(directory2):\n",
    "        count += len(files)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "382055df-b9b0-413e-9a8a-5e743db5353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of samples:  241340\n",
      "total number of steps:  7541\n",
      "Features shape: (32, 96, 64)\n",
      "Labels shape: (32, 2)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "porn_dir = r'A:\\AI DB\\LSPD\\Audio\\porn'\n",
    "normal_dir = r'A:\\AI DB\\LSPD\\Audio\\normal'\n",
    "batch_size = 32\n",
    "total_files=count_files(porn_dir, normal_dir)\n",
    "print(\"total number of samples: \",str(total_files))\n",
    "steps_per_epochs=int(total_files/batch_size)\n",
    "print(\"total number of steps: \",str(steps_per_epochs))\n",
    "file_paths, labels = _get_file_paths_and_labels(porn_dir, normal_dir)\n",
    "features, labels = _get_real_audio_examples_batch(file_paths, labels, batch_size)\n",
    "features=np.squeeze(features, axis=1)\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a15f6d05-2a64-4462-9162-1eb908fad9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99%  : loss 0.240975\n"
     ]
    }
   ],
   "source": [
    "_NUM_CLASSES=2\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # Define VGGish.\n",
    "    embeddings = vggish_slim.define_vggish_slim(training=False)\n",
    "\n",
    "    # Define a shallow classification model and associated training ops on top\n",
    "    # of VGGish.\n",
    "    with tf.variable_scope('mymodel'):\n",
    "      # Add a fully connected layer with 100 units. Add an activation function\n",
    "      # to the embeddings since they are pre-activation.\n",
    "      num_units = 100\n",
    "      fc = slim.fully_connected(tf.nn.relu(embeddings), num_units)\n",
    "\n",
    "      # Add a classifier layer at the end, consisting of parallel logistic\n",
    "      # classifiers, one per class. This allows for multi-class tasks.\n",
    "      logits = slim.fully_connected(\n",
    "          fc, _NUM_CLASSES, activation_fn=None, scope='logits')\n",
    "      tf.sigmoid(logits, name='prediction')\n",
    "\n",
    "      # Add training ops.\n",
    "      with tf.variable_scope('train'):\n",
    "        global_step = tf.train.create_global_step()\n",
    "\n",
    "        # Labels are assumed to be fed as a batch multi-hot vectors, with\n",
    "        # a 1 in the position of each positive class label, and 0 elsewhere.\n",
    "        labels_input = tf.placeholder(\n",
    "            tf.float32, shape=(None, _NUM_CLASSES), name='labels')\n",
    "\n",
    "        # Cross-entropy label loss.\n",
    "        xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels_input, name='xent')\n",
    "        loss = tf.reduce_mean(xent, name='loss_op')\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "        # We use the same optimizer and hyperparameters as used to train VGGish.\n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=vggish_params.LEARNING_RATE,\n",
    "            epsilon=vggish_params.ADAM_EPSILON)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Initialize all variables in the model, and then load the pre-trained\n",
    "    # VGGish checkpoint.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, 'vggish_model.ckpt')\n",
    "\n",
    "    # The training loop.\n",
    "    features_input = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.INPUT_TENSOR_NAME)\n",
    "    for _ in range(steps_per_epochs):\n",
    "        file_paths, labels = _get_file_paths_and_labels(porn_dir, normal_dir)\n",
    "        (features, labels) = _get_real_audio_examples_batch(file_paths, labels, batch_size)\n",
    "        features=np.squeeze(features, axis=1)\n",
    "        [num_steps, loss_value, _] = sess.run(\n",
    "            [global_step, loss, train_op],\n",
    "            feed_dict={features_input:features , labels_input: labels})\n",
    "        clear_output(wait=True)\n",
    "        percentage = (num_steps / steps_per_epochs) * 100.0\n",
    "        formatted_percentage = \"%.2f%%\" % percentage\n",
    "        print('%s  : loss %g' % (formatted_percentage, loss_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e95d1a-9961-4bd2-ab78-5bd3b1211773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6145a8dd-f55b-4fa9-a217-09f500e9f579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'vggish_2/input_features' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\3136552820.py\", line 14, in <module>\n      train_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=True)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 17, in __init__\n      self.sess, self.features_tensor, self.embeddings_tensor = self.load_vggish_model()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 20, in load_vggish_model\n      embeddings_tensor = vggish_slim.define_vggish_slim(training=False)\n    File \"C:\\Users\\Mohamed ali\\PFE\\vggish_slim.py\", line 83, in define_vggish_slim\n      features_tensor = tf.placeholder(\nNode: 'vggish_2/input_features'\nDetected at node 'vggish_2/input_features' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\3136552820.py\", line 14, in <module>\n      train_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=True)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 17, in __init__\n      self.sess, self.features_tensor, self.embeddings_tensor = self.load_vggish_model()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 20, in load_vggish_model\n      embeddings_tensor = vggish_slim.define_vggish_slim(training=False)\n    File \"C:\\Users\\Mohamed ali\\PFE\\vggish_slim.py\", line 83, in define_vggish_slim\n      features_tensor = tf.placeholder(\nNode: 'vggish_2/input_features'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'vggish_2/input_features' with dtype float and shape [?,96,64]\n\t [[{{node vggish_2/input_features}}]]\n\t [[vggish_2/embedding/_37]]\n  (1) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'vggish_2/input_features' with dtype float and shape [?,96,64]\n\t [[{{node vggish_2/input_features}}]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'vggish_2/input_features':\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n    result = runner(coro)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\3136552820.py\", line 14, in <module>\n    train_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=True)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 17, in __init__\n    self.sess, self.features_tensor, self.embeddings_tensor = self.load_vggish_model()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 20, in load_vggish_model\n    embeddings_tensor = vggish_slim.define_vggish_slim(training=False)\n  File \"C:\\Users\\Mohamed ali\\PFE\\vggish_slim.py\", line 83, in define_vggish_slim\n    features_tensor = tf.placeholder(\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 3345, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6897, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'vggish_2/input_features' with dtype float and shape [?,96,64]\n\t [[{{node vggish_2/input_features}}]]\n\t [[vggish_2/embedding/_37]]\n  (1) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'vggish_2/input_features' with dtype float and shape [?,96,64]\n\t [[{{node vggish_2/input_features}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model using the generator\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_classifier.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training_v1.py:855\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    854\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training_generator_v1.py:648\u001b[0m, in \u001b[0;36mGeneratorOrSequenceTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps_per_epoch, x)\n\u001b[0;32m    645\u001b[0m training_utils_v1\u001b[38;5;241m.\u001b[39mcheck_generator_arguments(\n\u001b[0;32m    646\u001b[0m     y, sample_weight, validation_split\u001b[38;5;241m=\u001b[39mvalidation_split\n\u001b[0;32m    647\u001b[0m )\n\u001b[1;32m--> 648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training_generator_v1.py:239\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m step \u001b[38;5;241m<\u001b[39m target_steps:\n\u001b[1;32m--> 239\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m \u001b[43m_get_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_dataset:\n\u001b[0;32m    242\u001b[0m             \u001b[38;5;66;03m# The dataset passed by the user ran out of batches.  Now we\u001b[39;00m\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;66;03m# know the cardinality of the dataset.  If steps_per_epoch\u001b[39;00m\n\u001b[0;32m    244\u001b[0m             \u001b[38;5;66;03m# was specified, then running out of data is unexpected, so\u001b[39;00m\n\u001b[0;32m    245\u001b[0m             \u001b[38;5;66;03m# we stop training and inform the user.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training_generator_v1.py:386\u001b[0m, in \u001b[0;36m_get_next_batch\u001b[1;34m(generator)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     generator_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mStopIteration\u001b[39;00m, tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOutOfRangeError):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\data_utils.py:819\u001b[0m, in \u001b[0;36mOrderedEnqueuer.get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m--> 819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\data_utils.py:810\u001b[0m, in \u001b[0;36mOrderedEnqueuer.get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m    812\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mtask_done()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\data_utils.py:596\u001b[0m, in \u001b[0;36mget_index\u001b[1;34m(uid, i)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_index\u001b[39m(uid, i):\n\u001b[0;32m    583\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the value from the Sequence `uid` at index `i`.\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \n\u001b[0;32m    585\u001b[0m \u001b[38;5;124;03m    To allow multiple Sequences to be used at the same time, we use `uid` to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;124;03m        The value at index `i`.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SHARED_SEQUENCES\u001b[49m\u001b[43m[\u001b[49m\u001b[43muid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 32\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     30\u001b[0m batch_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_paths[index \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m     31\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m---> 32\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "Cell \u001b[1;32mIn[9], line 45\u001b[0m, in \u001b[0;36mDataGenerator.__data_generation\u001b[1;34m(self, batch_paths, batch_labels)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (file_path, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(batch_paths, batch_labels)):\n\u001b[0;32m     44\u001b[0m     examples_batch \u001b[38;5;241m=\u001b[39m vggish_input\u001b[38;5;241m.\u001b[39mwavfile_to_examples(file_path)\n\u001b[1;32m---> 45\u001b[0m     [embeddings] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_tensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_tensor\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples_batch\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     embeddings_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Average embeddings across examples\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     X[i,] \u001b[38;5;241m=\u001b[39m embeddings_mean\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[0;32m   1393\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1394\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1395\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1396\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1397\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'vggish_2/input_features' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\3136552820.py\", line 14, in <module>\n      train_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=True)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 17, in __init__\n      self.sess, self.features_tensor, self.embeddings_tensor = self.load_vggish_model()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 20, in load_vggish_model\n      embeddings_tensor = vggish_slim.define_vggish_slim(training=False)\n    File \"C:\\Users\\Mohamed ali\\PFE\\vggish_slim.py\", line 83, in define_vggish_slim\n      features_tensor = tf.placeholder(\nNode: 'vggish_2/input_features'\nDetected at node 'vggish_2/input_features' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\3136552820.py\", line 14, in <module>\n      train_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=True)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 17, in __init__\n      self.sess, self.features_tensor, self.embeddings_tensor = self.load_vggish_model()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 20, in load_vggish_model\n      embeddings_tensor = vggish_slim.define_vggish_slim(training=False)\n    File \"C:\\Users\\Mohamed ali\\PFE\\vggish_slim.py\", line 83, in define_vggish_slim\n      features_tensor = tf.placeholder(\nNode: 'vggish_2/input_features'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'vggish_2/input_features' with dtype float and shape [?,96,64]\n\t [[{{node vggish_2/input_features}}]]\n\t [[vggish_2/embedding/_37]]\n  (1) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'vggish_2/input_features' with dtype float and shape [?,96,64]\n\t [[{{node vggish_2/input_features}}]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'vggish_2/input_features':\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n    result = runner(coro)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\3136552820.py\", line 14, in <module>\n    train_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=True)\n  File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 17, in __init__\n    self.sess, self.features_tensor, self.embeddings_tensor = self.load_vggish_model()\n  File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_16580\\4043747301.py\", line 20, in load_vggish_model\n    embeddings_tensor = vggish_slim.define_vggish_slim(training=False)\n  File \"C:\\Users\\Mohamed ali\\PFE\\vggish_slim.py\", line 83, in define_vggish_slim\n    features_tensor = tf.placeholder(\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 3345, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6897, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 797, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3800, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# Initialize data generator\n",
    "data_dir = r'A:\\AI DB\\LSPD\\Audio'\n",
    "batch_size = 32\n",
    "data_generator = DataGenerator(data_dir, batch_size=batch_size)\n",
    "\n",
    "# Split the data paths into training and validation sets\n",
    "file_paths, labels = data_generator.file_paths, data_generator.labels\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data generators for training and validation\n",
    "train_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=True)\n",
    "val_generator = DataGenerator(data_dir, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(128,)),  # VGGish embeddings are 128-D\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(data_generator.class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the generator\n",
    "model.fit(train_generator, epochs=20, validation_data=val_generator)\n",
    "\n",
    "# Save the model\n",
    "model.save('audio_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee50050-20d8-42da-9a12-352158aa41bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
