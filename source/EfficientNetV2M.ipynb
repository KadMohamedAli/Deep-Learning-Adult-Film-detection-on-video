{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0232559-f163-47c6-a402-a5b2705a283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2M\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6aa3c15-19c1-4a43-870b-a8f71fc976cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(image):\n",
    "    # Add custom preprocessing logic here if needed\n",
    "    return image\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "def create_generators(train_dir, validation_dir, test_dir, img_height, img_width, batch_size):\n",
    "    train_datagen = create_datagen()\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "def build_model(img_height, img_width):\n",
    "    base_model = EfficientNetV2M(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, save_path, monitor='val_accuracy', mode='max', verbose=1):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.save_path = save_path\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if self.best_weights is None:\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.best = current\n",
    "        else:\n",
    "            if (self.mode == 'max' and current > self.best) or (self.mode == 'min' and current < self.best):\n",
    "                self.best = current\n",
    "                self.best_weights = self.model.get_weights()\n",
    "                if self.verbose > 0:\n",
    "                    print(f'\\nEpoch {epoch+1}: {self.monitor} improved to {self.best}, saving model to {self.save_path}')\n",
    "                self.model.save(self.save_path)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def create_callbacks(save_path):\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    checkpoint = CustomModelCheckpoint(\n",
    "        save_path=save_path,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    return [lr_scheduler, early_stopping, checkpoint]\n",
    "\n",
    "def train(train_dir, validation_dir, test_dir, img_height, img_width, batch_size, save_path):\n",
    "    train_generator, validation_generator, test_generator = create_generators(\n",
    "        train_dir, validation_dir, test_dir, img_height, img_width, batch_size)\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    model = build_model(img_height, img_width)\n",
    "    callbacks = create_callbacks(save_path)\n",
    "\n",
    "    # Initial training with frozen layers\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Unfreeze the last block of layers and recompile\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Continue training with unfrozen layers\n",
    "    history_unfrozen = model.fit(\n",
    "        train_generator,\n",
    "        epochs=6,\n",
    "        initial_epoch=4,\n",
    "        validation_data=validation_generator,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Combine histories\n",
    "    for key in history.history.keys():\n",
    "        history.history[key].extend(history_unfrozen.history[key])\n",
    "\n",
    "    return history\n",
    "\n",
    "def predict_classes(test_generator, model):\n",
    "    ypred = model.predict(test_generator)\n",
    "    return ypred\n",
    "\n",
    "def evaluate_model(ypred, y_true_classes, threshold=0.5):\n",
    "    y_pred_classes = (ypred > threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    cr = classification_report(y_true_classes, y_pred_classes, digits=4)\n",
    "    print(\"Classification Report:\\n\", cr)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, cmap='YlGnBu', fmt='d', xticklabels=['Normal', 'Porn'], yticklabels=['Normal', 'Porn'], annot_kws={'size': 16})\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j + 0.5, i + 0.2, '{:.2f}%'.format(cm_normalized[i, j] * 100), ha='center', va='bottom', color='black', fontsize=14)\n",
    "\n",
    "    plt.ylabel('Actual', fontsize=12)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    print(\"Accuracy Score:\", format(accuracy, '.4f'))\n",
    "\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes)\n",
    "    print(\"F1 Score:\", format(f1, '.4f'))\n",
    "\n",
    "def tune_threshold(test_generator, model):\n",
    "    ypred = model.predict(test_generator)\n",
    "    thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred_classes = (ypred > threshold).astype(int)\n",
    "        f1 = f1_score(test_generator.classes, y_pred_classes)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"Best threshold: {best_threshold} with F1 score: {best_f1}\")\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dd8b388-bfa4-41f0-9d2b-029c8d4473ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'A:\\AI DB\\LSPD\\Videos\\photos_from_videos_pret\\train'\n",
    "validation_dir = r'A:\\AI DB\\LSPD\\Videos\\photos_from_videos_pret\\val'\n",
    "test_dir = r'A:\\AI DB\\LSPD\\Videos\\photos_from_videos_pret\\test'\n",
    "save_path = r'A:\\AI DB\\LSPD\\models\\efficient_trained_on_videos.keras'\n",
    "img_height, img_width = 380, 380\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978d8f64-fb75-4f58-9c61-3de296b22a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts:\n",
      "Found 430877 images belonging to 2 classes.\n",
      "Found 23937 images belonging to 2 classes.\n",
      "Found 23939 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "6733/6733 [==============================] - 11038s 2s/step - loss: 0.6794 - accuracy: 0.5651 - val_loss: 0.6631 - val_accuracy: 0.6084 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "6733/6733 [==============================] - 10932s 2s/step - loss: 0.6733 - accuracy: 0.5804 - val_loss: 0.6813 - val_accuracy: 0.5451 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "6733/6733 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.5886\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "6733/6733 [==============================] - 11080s 2s/step - loss: 0.6697 - accuracy: 0.5886 - val_loss: 0.6697 - val_accuracy: 0.5835 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "6733/6733 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.5994\n",
      "Epoch 4: val_accuracy improved to 0.6188745498657227, saving model to A:\\AI DB\\LSPD\\models\\efficient_trained_on_videos.keras\n",
      "6733/6733 [==============================] - 10920s 2s/step - loss: 0.6650 - accuracy: 0.5994 - val_loss: 0.6550 - val_accuracy: 0.6189 - lr: 5.0000e-04\n",
      "Epoch 5/5\n",
      "6733/6733 [==============================] - 10913s 2s/step - loss: 0.6632 - accuracy: 0.6014 - val_loss: 0.6667 - val_accuracy: 0.5883 - lr: 5.0000e-04\n",
      "Epoch 5/6\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/block2b_expand_activation/Sigmoid' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_14296\\766174538.py\", line 3, in <module>\n      histories = train(train_dir, validation_dir, test_dir, img_height, img_width, batch_size, save_path)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_14296\\733006064.py\", line 142, in train\n      history_unfrozen = model.fit(\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\layers\\core\\activation.py\", line 59, in call\n      return self.activation(inputs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\activations.py\", line 276, in swish\n      return tf.nn.silu(x)\nNode: 'model_1/block2b_expand_activation/Sigmoid'\nfailed to allocate memory\n\t [[{{node model_1/block2b_expand_activation/Sigmoid}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_272324]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining starts:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m histories \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 142\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dir, validation_dir, test_dir, img_height, img_width, batch_size, save_path)\u001b[0m\n\u001b[0;32m    139\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Continue training with unfrozen layers\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m history_unfrozen \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Combine histories\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/block2b_expand_activation/Sigmoid' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Mohamed ali\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_14296\\766174538.py\", line 3, in <module>\n      histories = train(train_dir, validation_dir, test_dir, img_height, img_width, batch_size, save_path)\n    File \"C:\\Users\\Mohamed ali\\AppData\\Local\\Temp\\ipykernel_14296\\733006064.py\", line 142, in train\n      history_unfrozen = model.fit(\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\layers\\core\\activation.py\", line 59, in call\n      return self.activation(inputs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\amchibrk\\lib\\site-packages\\keras\\activations.py\", line 276, in swish\n      return tf.nn.silu(x)\nNode: 'model_1/block2b_expand_activation/Sigmoid'\nfailed to allocate memory\n\t [[{{node model_1/block2b_expand_activation/Sigmoid}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_272324]"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "print(\"Training starts:\")\n",
    "histories = train(train_dir, validation_dir, test_dir, img_height, img_width, batch_size, save_path)\n",
    "\n",
    "print(\"Training finished.\")\n",
    "# Load the best model\n",
    "model = tf.keras.models.load_model(save_path)\n",
    "\n",
    "# Predict classes for evaluation\n",
    "ypred = predict_classes(test_generator, model)\n",
    "\n",
    "print(\"Evaluation:\")\n",
    "evaluate_model(ypred, test_generator.classes)\n",
    "\n",
    "print(\"Calculating best threshold:\")\n",
    "best_threshold = tune_threshold(test_generator, model)\n",
    "\n",
    "print(\"Re-evaluation with best threshold:\")\n",
    "evaluate_model(ypred, test_generator.classes, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743846a4-3758-45be-86c0-43c4a22aac36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
